{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# En primer lugar, consideraremos como banco de prueba la estación con mediciones más antiguas\n",
    "# Se trata de la estacion localizada en Milan que tiene información desde 1763\n",
    "import sqlite3\n",
    "\n",
    "# Abrimos la conexión con la BBDD\n",
    "conn = sqlite3.connect(\"D:/master/Master-in-Data-Science/Proyecto/Datos/worldTimeSeries.sqlite\")\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas import DataFrame,Series\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Realizamos la query\n",
    "station = 'ITE00100554'\n",
    "\n",
    "# Se calcula la temperatura media por cada uno de los meses\n",
    "rows = cursor.execute(\"\"\"select \n",
    "                            date, \n",
    "                            TMAX, \n",
    "                            TMIN, \n",
    "                            PRCP\n",
    "                        from world_time_europa\n",
    "                        where STATION = '\"\"\"+station+\"';\")\n",
    "\n",
    "n = 0\n",
    "for r in rows:\n",
    "    n = n+1\n",
    "print(\"Numero de registros:\" + str(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tenemos una serie temporal con un total de 89,786 registros, lo que para hacer un análisis inicial es un nivel \n",
    "# muy detallado por tanto, vamos a reducir el conjunto de datos realizando la media de cada unidad por año\n",
    "# Realizamos la query\n",
    "station = 'ITE00100554'\n",
    "result=[]\n",
    "\n",
    "# Se calcula la temperatura media por cada uno de los meses\n",
    "rows = cursor.execute(\"\"\"select \n",
    "                            substr(date,1,4) as date, \n",
    "                            avg(TMAX) as TMAX, \n",
    "                            avg(TMIN) as TMIN, \n",
    "                            avg(PRCP) as PRCP,\n",
    "                            count(*) as NOBS\n",
    "                        from world_time_europa\n",
    "                        where STATION = '\"\"\"+station+\"\"\"'\n",
    "                        group by substr(date,1,4)\n",
    "                        order by substr(date,1,4);\"\"\")\n",
    "n = 0\n",
    "for r in rows:\n",
    "    n = n+1\n",
    "    result.append({\"date\":r[0],\"TMAX\":r[1],\"TMIN\":r[2],\"PRCP\":r[3],\"NOBS\":r[4]})\n",
    "    \n",
    "print(\"Numero de registros:\" + str(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(df.date,df.TMAX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(df.date,df.TMIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(df.date,df.PRCP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Se observa que efectivamente en los últimos años de la serie se presentan anomalías en los 3 indicadores, pero no tenemos la información completa, ya que el último dato disponible de la estación data de 2008, por tanto tenemos que localizar una estacion en una localización con similares características para poder extrapolar las medidas de la estación de Milan con esa nueva localizacion.\n",
    "\n",
    "¿Desde que fecha debemos completar?\n",
    "\n",
    "La serie se trunca en 2008, pero los datos anómalos que se observan desde 2006 parecen indicar anomalias en las observaciones, ya que rompe totalmente y muy bruscamente los datos. Si observamos la serie histórica, cada año hay 365 o 366 observaciones, salvo en los años de 2007 y 2008 que presentan 331 y 336 observaciones respectivamente, es decir que falta al menos 1 mes de observaciones, si esa falta estuviera distribuida uniformemente por todo el año podríamos inferir que la anomalía no es debida a esa falta de información, pero si sacamos el número de observaciones por mes, vemos que en 2007 faltan 4 días de Julio y 30 de Octubre, un mes en el que las temperaturas se reducen, por tanto podría explicar la subida en la temperatura media anual en 2 grados\n",
    "\n",
    "Para 2008, se observa que faltan 30 días de Diciembre, el primer mes de invierno, que puede explicar el incremento observado en temperaturas y reducción de precipitaciones\n",
    "\n",
    "En 2006, a pesar de ser el primer año con anomalías, parece que no es debido al tamaño de los datos, por tanto consideraremos que ese año la información es correcta. Por tanto para completar la información de la serie de Milan debemos buscar las observaciones de la estacion meteorológica más parecida desde el año 2007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Para los años 2007 y 2008 revisamos qué días del año faltan\n",
    "station = 'ITE00100554'\n",
    "\n",
    "# Se calcula la temperatura media por cada uno de los meses\n",
    "rows = cursor.execute(\"\"\"select \n",
    "                            substr(date,1,6) as date, \n",
    "                            count(*) as NOBS\n",
    "                        from world_time_europa\n",
    "                        where STATION = '\"\"\"+station+\"\"\"' and date >= \"20070101\" and date <= \"20081231\"\n",
    "                        group by substr(date,1,6)\n",
    "                        order by substr(date,1,6);\"\"\")\n",
    "result_2007=[]\n",
    "result_2008=[]\n",
    "for r in rows:\n",
    "    if r[0] <= \"200712\":\n",
    "        result_2007.append({\"date\":r[0],\"NOBS\":r[1]})\n",
    "    else:\n",
    "        result_2008.append({\"date\":r[0],\"NOBS\":r[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_2007 = DataFrame(result_2007)\n",
    "df_2008 = DataFrame(result_2008)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_2007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_2008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "En ambos casos falta información de 1 mes de otoño/invierno, justo cuando las temperaturas son más bajas, por tanto los picos observados en 2007 y 2008 no son válidos\n",
    "\n",
    "Con los resultados anteriores, y para poder completar la historia completa de la estacion, es necesario buscar la estacion mas cercana a los resultados obtenidos para completar las observaciones de la estacion a partir de 2006, se realiza la busqueda para cada uno de los continentes, sacando el ranking de estaciones similares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Funcion para la busqueda de estación más parecida a una dada\n",
    "def findSimilarStationRanking(station, continent_table, bbdd_cursor):\n",
    "    ranking=DataFrame()\n",
    "\n",
    "    # En primer lugar se leen todas las estaciones del hemisferio sur (latitud negativa)\n",
    "    df_hemis_sur = pd.read_csv(\"D:/master/Master-in-Data-Science/Proyecto/Datos/ghcnd-stations-cluster.csv\",\n",
    "                                sep=\";\",decimal=\",\")\n",
    "    df_hemis_sur['station'] = df_hemis_sur.COUNTRY + df_hemis_sur.ID\n",
    "    df_hemis_sur = df_hemis_sur[df_hemis_sur.LATITUDE < 0][['station']]\n",
    "    \n",
    "    # En primer lugar buscamos la estacion en el continente indicado\n",
    "    rows = bbdd_cursor.execute(\"select date, TMAX, TMIN, PRCP from \"+continent_table+\" where station = '\"+station+\"';\")\n",
    "    \n",
    "    is_south_master = False\n",
    "    if max(df_hemis_sur.station.isin([station])):\n",
    "        is_south_master = True\n",
    "    \n",
    "    result_north=[]\n",
    "    result_south=[]\n",
    "    for r in rows:\n",
    "        # Se convierte la fecha a formato fecha\n",
    "        if is_south_master:\n",
    "            date_south = r[0]\n",
    "            date_north = datetime.strptime(r[0], '%Y%m%d') - pd.DateOffset(months=6)\n",
    "            #date_north = date_north.strftime(\"%Y%m%d\")\n",
    "            date_north = str(date_north.year) + str(date_north.month) + str(date_north.day)\n",
    "        else:\n",
    "            date_north = r[0]\n",
    "            date_south = datetime.strptime(r[0], '%Y%m%d') + pd.DateOffset(months=6)\n",
    "            #date_south = date_south.strftime(\"%Y%m%d\")\n",
    "            date_south = str(date_south.year) + str(date_south.month) + str(date_south.day)\n",
    "                        \n",
    "                        \n",
    "        result_north.append({\"date\":date_north,\"ROOT_TMAX\":r[1],\"ROOT_TMIN\":r[2],\"ROOT_PRCP\":r[3]})        \n",
    "        result_south.append({\"date\":date_south,\"ROOT_TMAX\":r[1],\"ROOT_TMIN\":r[2],\"ROOT_PRCP\":r[3]})        \n",
    "\n",
    "    df_root_station_north = DataFrame(result_north)\n",
    "    df_root_station_south = DataFrame(result_south)\n",
    "    result_north = []\n",
    "    result_south = []\n",
    "\n",
    "    # Para cada continente, se itera por pais, para recuperar y comparar la informacion de cada estacion\n",
    "    continentes=[\"antarctica\",\"central_america\",\"south_america\",\"north_america\",\"europa\",\"africa\",\"asia\",\"oceania\"]\n",
    "    for continente in continentes:  \n",
    "        print (\"Iterando con el continente \" + continente)\n",
    "        rows = bbdd_cursor.execute(\"\"\"select station, date, TMAX, TMIN, PRCP \n",
    "                    from world_time_\"\"\"+continente+\" order by station;\")\n",
    "        \n",
    "        n = 0\n",
    "        result = []\n",
    "        for r_stat in rows:\n",
    "            # Se recuperan todas las observaciones de cada estacion\n",
    "            s = r_stat[0]\n",
    "            if n == 0:\n",
    "                current_station = s\n",
    "                \n",
    "            date = r_stat[1]      \n",
    "            tmax = r_stat[2]\n",
    "            tmin = r_stat[3]\n",
    "            prcp = r_stat[4]\n",
    "                \n",
    "            n = n + 1\n",
    "\n",
    "            # Se compara con la estacion maestra, si es igual, no se hace nada, en otro caso se construye el\n",
    "            # DataFrame con el detalle de las observaciones\n",
    "            if current_station != station:                \n",
    "                if s == current_station:\n",
    "                    # Seguimos construyendo el DataFrame de la estacion\n",
    "                    result.append({\"station\":s, \"date\":date,\"TMAX\":tmax,\"TMIN\":tmin,\"PRCP\":prcp})\n",
    "                else:\n",
    "                    # Llegamos a la primera observacion de la siguiente estacion\n",
    "                    # El conjunto de observaciones de la estacion previa se convierten en un DataFrame\n",
    "                    df_station = DataFrame(result)\n",
    "                    df_station = df_station.fillna(0)\n",
    "        \n",
    "                    # Con la estacion recuperada, realizamos el merge con la estacion buscada\n",
    "                    df_station_north = df_station.merge(df_root_station_north[[\"date\",\"ROOT_TMAX\",\"ROOT_TMIN\",\"ROOT_PRCP\"]],\n",
    "                                                        on='date')\n",
    "                    df_station_south = df_station.merge(df_root_station_south[[\"date\",\"ROOT_TMAX\",\"ROOT_TMIN\",\"ROOT_PRCP\"]],\n",
    "                                                        on='date')\n",
    "                    df_station=DataFrame()\n",
    "\n",
    "                    # Se calcula la diferencia entre cada una de las medidas con los datos hemisferio norte\n",
    "                    df_station_north[\"DIFF_TMAX\"] = pow(df_station_north[\"ROOT_TMAX\"]-df_station_north[\"TMAX\"],2)\n",
    "                    df_station_north[\"DIFF_TMIN\"] = pow(df_station_north[\"ROOT_TMIN\"]-df_station_north[\"TMIN\"],2)\n",
    "                    df_station_north[\"DIFF_PRCP\"] = pow(df_station_north[\"ROOT_PRCP\"]-df_station_north[\"PRCP\"],2)\n",
    "                    df_station_north[\"NRECORDS\"] = 1\n",
    "                    \n",
    "                    df_station_north = df_station_north[[\"station\",\"date\",\"DIFF_TMAX\",\"DIFF_TMIN\",\"DIFF_PRCP\",\"NRECORDS\"]]\n",
    "                    df_station_north = df_station_north.groupby(\"station\").sum()\n",
    "                    df_station_north.reset_index()\n",
    "                    \n",
    "                    df_station_north[\"TMAX\"] = pow(df_station_north[\"DIFF_TMAX\"]/df_station_north[\"NRECORDS\"],0.5)\n",
    "                    df_station_north[\"TMIN\"] = pow(df_station_north[\"DIFF_TMIN\"]/df_station_north[\"NRECORDS\"],0.5)\n",
    "                    df_station_north[\"PRCP\"] = pow(df_station_north[\"DIFF_PRCP\"]/df_station_north[\"NRECORDS\"],0.5)\n",
    "                    df_station_north['SIMILARIDAD'] = (df_station_north['TMAX']+df_station_north['TMIN'])/2\n",
    "                    #df_station_north = df_station_north[[\"station\",\"TMAX\",\"TMIN\",\"PRCP\",\"NRECORDS\"]]\n",
    "\n",
    "                    \n",
    "                    # Se calcula la diferencia entre cada una de las medidas con los datos hemisferio sur\n",
    "                    df_station_south[\"DIFF_TMAX\"] = pow(df_station_south[\"ROOT_TMAX\"]-df_station_south[\"TMAX\"],2)\n",
    "                    df_station_south[\"DIFF_TMIN\"] = pow(df_station_south[\"ROOT_TMIN\"]-df_station_south[\"TMIN\"],2)\n",
    "                    df_station_south[\"DIFF_PRCP\"] = pow(df_station_south[\"ROOT_PRCP\"]-df_station_south[\"PRCP\"],2)\n",
    "                    df_station_south[\"NRECORDS\"] = 1\n",
    "    \n",
    "                    df_station_south = df_station_south[[\"station\",\"date\",\"DIFF_TMAX\",\"DIFF_TMIN\",\"DIFF_PRCP\",\"NRECORDS\"]]\n",
    "                    df_station_south = df_station_south.groupby(\"station\").sum()\n",
    "                    df_station_south.reset_index()\n",
    "                \n",
    "                    df_station_south[\"TMAX\"] = pow(df_station_south[\"DIFF_TMAX\"]/df_station_south[\"NRECORDS\"],0.5)\n",
    "                    df_station_south[\"TMIN\"] = pow(df_station_south[\"DIFF_TMIN\"]/df_station_south[\"NRECORDS\"],0.5)\n",
    "                    df_station_south[\"PRCP\"] = pow(df_station_south[\"DIFF_PRCP\"]/df_station_south[\"NRECORDS\"],0.5)\n",
    "                    df_station_south['SIMILARIDAD'] = (df_station_south['TMAX']+df_station_south['TMIN'])/2\n",
    "                    #df_station_south = df_station_south[[\"station\",\"TMAX\",\"TMIN\",\"PRCP\",\"NRECORDS\"]]\n",
    "                    \n",
    "                    # Se guardan los resultados de la comparativa\n",
    "\n",
    "                    if len(df_station_north) > 0 and len(df_station_south > 0):\n",
    "                        if df_station_north.SIMILARIDAD[0] <= df_station_south.SIMILARIDAD[0]:            \n",
    "                            ranking = ranking.append(df_station_north)\n",
    "                        else:\n",
    "                            ranking = ranking.append(df_station_south)\n",
    "                        \n",
    "                    df_station_north = DataFrame()\n",
    "                    df_station_south = DataFrame()\n",
    "                   \n",
    "                    # Se inicializan las variables para que funcione correctamente el bucle\n",
    "                    result = []\n",
    "                    current_station = s                    \n",
    "                    result.append({\"station\":s, \"date\":date,\"TMAX\":tmax,\"TMIN\":tmin,\"PRCP\":prcp})\n",
    "            \n",
    "    ranking = ranking.sort_values(by=\"SIMILARIDAD\")\n",
    "    print (ranking.head())\n",
    "    ranking.to_csv(station+\"_similarity.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "from pandas import DataFrame,Series\n",
    "# Abrimos la conexión con la BBDD\n",
    "conn = sqlite3.connect(\"D:/master/Master-in-Data-Science/Proyecto/Datos/worldTimeSeries.sqlite\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "findSimilarStationRanking('ITE00100554', 'world_time_europa', cursor)\n",
    "\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
